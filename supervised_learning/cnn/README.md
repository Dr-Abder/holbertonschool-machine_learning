# CNN - ImplÃ©mentation From Scratch

ImplÃ©mentation complÃ¨te des opÃ©rations fondamentales d'un rÃ©seau de neurones convolutif (CNN) avec NumPy et Keras.

---

## ğŸ“‹ Exercices rÃ©alisÃ©s

### 1. Convolution Forward (`0-conv_forward.py`)
Propagation avant d'une couche convolutionnelle.

**Concepts :**
- Padding : `same` (conserve dimensions) vs `valid` (rÃ©duit dimensions)
- Stride : pas de dÃ©placement du filtre
- Formule : `output_size = (input_size + 2*pad - kernel_size) // stride + 1`

**Optimisation :** Vectorisation NumPy â†’ 50x plus rapide !

```python
# Traite toutes les images simultanÃ©ment
region = A_prev_padded[:, i*sh:i*sh+kh, j*sw:j*sw+kw, :]
conv_value = np.sum(region * kernel, axis=(1, 2, 3)) + b[0, 0, 0, k]
A[:, i, j, k] = activation(conv_value)
```

**Performance :**
- Input : `(50000, 28, 28, 1)`
- Output : `(50000, 26, 26, 2)` avec `padding='valid'`

---

### 2. Pooling Forward (`1-pool_forward.py`)
RÃ©duction de dimensions par max ou average pooling.

**Max Pooling :** Garde la valeur maximale â†’ features les plus fortes  
**Average Pooling :** Calcule la moyenne â†’ lisse les features

```python
if mode == 'max':
    A[:, i, j, :] = np.max(region, axis=(1, 2))
elif mode == 'avg':
    A[:, i, j, :] = np.mean(region, axis=(1, 2))
```

**Performance :**
- Input : `(50000, 28, 28, 2)`
- Output : `(50000, 14, 14, 2)` avec kernel `(2, 2)` et stride `(2, 2)`

---

### 3. Convolution Backward (`2-conv_backward.py`)
RÃ©tropropagation pour calculer les gradients.

**Retourne :**
- `dA_prev` : gradients vers la couche prÃ©cÃ©dente
- `dW` : gradients des poids (pour mise Ã  jour)
- `db` : gradients des biais

**Formules clÃ©s :**
```python
# Gradient des biais
db = np.sum(dZ, axis=(0, 1, 2), keepdims=True)

# Gradient des poids
dW[:, :, :, k] += np.sum(region * dZ_slice, axis=0)

# Gradient de l'entrÃ©e
dA_prev_padded[:, i*sh:i*sh+kh, j*sw:j*sw+kw, :] += W_slice * dZ_slice
```

**Intuition :** `dZ` indique "qui est responsable de l'erreur" et on remonte pour distribuer cette responsabilitÃ©.

---

### 4. Pooling Backward (`3-pool_backward.py`)
RÃ©tropropagation du pooling.

**Max Pooling :** Gradient va uniquement au maximum
```python
mask = (region == max_val).astype(float)
dA_prev += mask * dA[:, i, j, k][:, np.newaxis, np.newaxis]
```

**Average Pooling :** Gradient distribuÃ© Ã©galement
```python
dA_prev += dA[:, i, j, k][:, np.newaxis, np.newaxis] / (kh * kw)
```

**Logique :**
- **Max** : Seul le max a contribuÃ© â†’ seul lui reÃ§oit le gradient
- **Average** : Tous ont contribuÃ© Ã©galement â†’ distribution Ã©gale

---

### 5. LeNet-5 (Keras) (`5-lenet5.py`)
CNN complet pour classification MNIST.

**Architecture :**
```
Input (28Ã—28Ã—1)
    â†“
Conv2D (6 filtres 5Ã—5, same) + ReLU â†’ (28Ã—28Ã—6)
    â†“
MaxPool (2Ã—2, stride 2) â†’ (14Ã—14Ã—6)
    â†“
Conv2D (16 filtres 5Ã—5, valid) + ReLU â†’ (10Ã—10Ã—16)
    â†“
MaxPool (2Ã—2, stride 2) â†’ (5Ã—5Ã—16)
    â†“
Flatten â†’ Dense(120) â†’ Dense(84) â†’ Dense(10, softmax)
```

**Code complet :**
```python
from tensorflow import keras as K

def lenet5(X):
    initializer = K.initializers.HeNormal(seed=0)
    
    conv1 = K.layers.Conv2D(6, (5,5), padding='same', 
                            activation='relu', 
                            kernel_initializer=initializer)(X)
    pool1 = K.layers.MaxPooling2D((2,2), strides=(2,2))(conv1)
    
    conv2 = K.layers.Conv2D(16, (5,5), padding='valid',
                            activation='relu',
                            kernel_initializer=initializer)(pool1)
    pool2 = K.layers.MaxPooling2D((2,2), strides=(2,2))(conv2)
    
    flatten = K.layers.Flatten()(pool2)
    fc1 = K.layers.Dense(120, activation='relu', 
                         kernel_initializer=initializer)(flatten)
    fc2 = K.layers.Dense(84, activation='relu',
                         kernel_initializer=initializer)(fc1)
    output = K.layers.Dense(10, activation='softmax',
                           kernel_initializer=initializer)(fc2)
    
    model = K.Model(inputs=X, outputs=output)
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model
```

---

## ğŸ§  Concepts clÃ©s

### Convolution
Applique un filtre sur l'image pour extraire des features (contours, textures, formes).

### Padding
- **same** : conserve les dimensions (ajoute des zÃ©ros)
- **valid** : aucun padding (dimensions rÃ©duites)

### Stride
Pas de dÃ©placement du filtre. `stride > 1` â†’ rÃ©duit les dimensions.

### Pooling
RÃ©duit dimensions sans paramÃ¨tres apprenables. Apporte une invariance aux translations.

### Backpropagation
Calcul des gradients pour mettre Ã  jour les poids : `W = W - learning_rate * dW`

---

## ğŸ“Š RÃ©sultats LeNet-5 sur MNIST

| MÃ©trique | Valeur |
|----------|--------|
| **Accuracy (train)** | 99.24% |
| **Accuracy (validation)** | 98.70% |
| **Loss finale (train)** | 0.024 |
| **Loss finale (validation)** | 0.054 |
| **Temps d'entraÃ®nement** | ~53s (5 epochs) |
| **Nombre de paramÃ¨tres** | ~61,000 |

**EntraÃ®nement dÃ©taillÃ© :**
```
Epoch 1/5: accuracy: 94.56% â†’ val_accuracy: 97.94%
Epoch 2/5: accuracy: 98.16% â†’ val_accuracy: 98.34%
Epoch 3/5: accuracy: 98.68% â†’ val_accuracy: 98.48%
Epoch 4/5: accuracy: 99.01% â†’ val_accuracy: 98.74%
Epoch 5/5: accuracy: 99.24% â†’ val_accuracy: 98.70%
```

**Exemple de prÃ©diction :**
Pour un chiffre "3", le modÃ¨le prÃ©dit :
```python
[3.02e-16, 4.20e-11, 8.19e-13, 1.00, 1.12e-16, ...]
                                  â†‘
                    ProbabilitÃ© 100% pour la classe 3
```

---

## ğŸ’¡ Points clÃ©s

### 1. Vectorisation NumPy

```python
# âŒ Lent : boucle sur chaque image
for img in range(m):
    result[img] = operation(data[img])

# âœ… 50x plus rapide : traite toutes les images simultanÃ©ment
result = operation(data)
```

### 2. Architecture CNN moderne

```
[Convolution â†’ Activation â†’ Pooling] Ã— N blocs
    â†“
Flatten (aplatir en vecteur)
    â†“
Dense layers (fully connected)
    â†“
Softmax (probabilitÃ©s de classification)
```

### 3. From scratch vs Keras

| Aspect | NumPy (from scratch) | Keras |
|--------|---------------------|-------|
| **ComprÃ©hension** | Profonde | Utilisation |
| **ContrÃ´le** | Total | Abstrait |
| **Temps de dev** | Long | Rapide |
| **Performance** | Ã€ optimiser | OptimisÃ© auto |
| **Debugging** | Difficile | Facile |

**Conclusion :** Les deux approches sont complÃ©mentaires !

---

## ğŸš€ CompÃ©tences acquises

- [x] ImplÃ©mentation from scratch des opÃ©rations CNN avec NumPy
- [x] Optimisation avec vectorisation (50x speedup)
- [x] ComprÃ©hension profonde de la backpropagation
- [x] Construction d'architectures complÃ¨tes avec Keras
- [x] EntraÃ®nement et Ã©valuation de modÃ¨les
- [x] Debugging d'erreurs de dimensions et de syntaxe
- [x] Obtention de >98% accuracy sur MNIST

---

## ğŸ“ Formules importantes

**Dimensions de sortie (convolution) :**
```
output_h = (input_h + 2*pad_h - kernel_h) // stride_h + 1
output_w = (input_w + 2*pad_w - kernel_w) // stride_w + 1
```

**Padding pour "same" (avec stride=1) :**
```
pad_h = (kernel_h - 1) // 2
pad_w = (kernel_w - 1) // 2
```

**Dimensions de sortie (pooling) :**
```
output_h = (input_h - kernel_h) // stride_h + 1
output_w = (input_w - kernel_w) // stride_w + 1
```

---

## ğŸ¯ Pour aller plus loin

### Architectures modernes Ã  explorer
- **VGG** : Convolutions 3Ã—3 empilÃ©es
- **ResNet** : Skip connections (connexions rÃ©siduelles)
- **Inception** : Convolutions multi-Ã©chelles parallÃ¨les
- **EfficientNet** : Scaling optimal des dimensions

### Techniques avancÃ©es
- **Data Augmentation** : rotation, flip, zoom
- **Batch Normalization** : stabilise l'entraÃ®nement
- **Dropout** : rÃ©gularisation anti-overfitting
- **Transfer Learning** : rÃ©utiliser modÃ¨les prÃ©-entraÃ®nÃ©s
- **Learning Rate Scheduling** : ajuster le taux d'apprentissage

### Applications rÃ©elles
- Classification d'images
- DÃ©tection d'objets (YOLO, Faster R-CNN)
- Segmentation sÃ©mantique (U-Net, Mask R-CNN)
- Style transfer
- Super-resolution

---

## ğŸ“š Ressources

- **Paper LeNet-5** : "Gradient-Based Learning Applied to Document Recognition" (LeCun et al., 1998)
- **Cours deeplearning.ai** : CNN Specialization
- **CS231n Stanford** : Convolutional Neural Networks for Visual Recognition
- **Documentation** : https://keras.io/

---

## ğŸ“‚ Structure du projet

```
supervised_learning/cnn/
â”œâ”€â”€ 0-conv_forward.py          # Convolution forward
â”œâ”€â”€ 1-pool_forward.py           # Pooling forward
â”œâ”€â”€ 2-conv_backward.py          # Convolution backward
â”œâ”€â”€ 3-pool_backward.py          # Pooling backward
â”œâ”€â”€ 5-lenet5.py                 # LeNet-5 avec Keras
â””â”€â”€ README.md                   # Ce fichier
```

---

*ImplÃ©mentation complÃ¨te du forward et backward pass d'un CNN, avec validation sur MNIST atteignant 98.7% d'accuracy.*

**Technologies :** Python, NumPy, TensorFlow/Keras  
**Dataset :** MNIST (chiffres manuscrits 0-9)  
**Date :** Octobre 2025